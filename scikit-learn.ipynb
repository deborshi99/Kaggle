{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-science-london-scikit-learn.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "!kaggle competitions download -c data-science-london-scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "file = os.listdir()\n",
    "if \"data\" in file:\n",
    "    for i in file:\n",
    "        if i.endswith(\".zip\"):\n",
    "            file_path = os.getcwd() + \"/\"+ i\n",
    "            ZipFile(file_path).extractall(os.getcwd()+\"/data\")\n",
    "else:\n",
    "    for i in file:\n",
    "        if i.endswith(\".zip\"):\n",
    "            os.makedirs(os.getcwd() + \"/data\")\n",
    "            file_path = os.getcwd() + \"/\"+ i\n",
    "            ZipFile(file_path).extractall(os.getcwd()+\"/data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def fetch_data():\n",
    "    train_data = pd.read_csv(\"D:\\my work\\kaggle\\sickit learn\\data\\\\train.csv\", header=None)\n",
    "    test_data = pd.read_csv(\"D:\\my work\\kaggle\\sickit learn\\data\\\\test.csv\", header=None)\n",
    "    sub_data = pd.read_csv(\"D:\\my work\\kaggle\\sickit learn\\data\\\\trainLabels.csv\", header=None)\n",
    "    return  train_data, test_data, sub_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "train_data, test_data, y_data = fetch_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "         0         1         2         3         4         5         6   \\\n0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n\n         7         8         9   ...        30        31        32        33  \\\n0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n\n         34        35        36        37        38        39  \n0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.299403</td>\n      <td>-1.226624</td>\n      <td>1.498425</td>\n      <td>-1.176150</td>\n      <td>5.289853</td>\n      <td>0.208297</td>\n      <td>2.404498</td>\n      <td>1.594506</td>\n      <td>-0.051608</td>\n      <td>0.663234</td>\n      <td>...</td>\n      <td>-0.850465</td>\n      <td>-0.622990</td>\n      <td>-1.833057</td>\n      <td>0.293024</td>\n      <td>3.552681</td>\n      <td>0.717611</td>\n      <td>3.305972</td>\n      <td>-2.715559</td>\n      <td>-2.682409</td>\n      <td>0.101050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.174176</td>\n      <td>0.332157</td>\n      <td>0.949919</td>\n      <td>-1.285328</td>\n      <td>2.199061</td>\n      <td>-0.151268</td>\n      <td>-0.427039</td>\n      <td>2.619246</td>\n      <td>-0.765884</td>\n      <td>-0.093780</td>\n      <td>...</td>\n      <td>-0.819750</td>\n      <td>0.012037</td>\n      <td>2.038836</td>\n      <td>0.468579</td>\n      <td>-0.517657</td>\n      <td>0.422326</td>\n      <td>0.803699</td>\n      <td>1.213219</td>\n      <td>1.382932</td>\n      <td>-1.817761</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.192222</td>\n      <td>-0.414371</td>\n      <td>0.067054</td>\n      <td>-2.233568</td>\n      <td>3.658881</td>\n      <td>0.089007</td>\n      <td>0.203439</td>\n      <td>-4.219054</td>\n      <td>-1.184919</td>\n      <td>-1.240310</td>\n      <td>...</td>\n      <td>-0.604501</td>\n      <td>0.750054</td>\n      <td>-3.360521</td>\n      <td>0.856988</td>\n      <td>-2.751451</td>\n      <td>-1.582735</td>\n      <td>1.672246</td>\n      <td>0.656438</td>\n      <td>-0.932473</td>\n      <td>2.987436</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.573270</td>\n      <td>-0.580318</td>\n      <td>-0.866332</td>\n      <td>-0.603812</td>\n      <td>3.125716</td>\n      <td>0.870321</td>\n      <td>-0.161992</td>\n      <td>4.499666</td>\n      <td>1.038741</td>\n      <td>-1.092716</td>\n      <td>...</td>\n      <td>1.022959</td>\n      <td>1.275598</td>\n      <td>-3.480110</td>\n      <td>-1.065252</td>\n      <td>2.153133</td>\n      <td>1.563539</td>\n      <td>2.767117</td>\n      <td>0.215748</td>\n      <td>0.619645</td>\n      <td>1.883397</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.613071</td>\n      <td>-0.644204</td>\n      <td>1.112558</td>\n      <td>-0.032397</td>\n      <td>3.490142</td>\n      <td>-0.011935</td>\n      <td>1.443521</td>\n      <td>-4.290282</td>\n      <td>-1.761308</td>\n      <td>0.807652</td>\n      <td>...</td>\n      <td>0.513906</td>\n      <td>-1.803473</td>\n      <td>0.518579</td>\n      <td>-0.205029</td>\n      <td>-4.744566</td>\n      <td>-1.520015</td>\n      <td>1.830651</td>\n      <td>0.870772</td>\n      <td>-1.894609</td>\n      <td>0.408332</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3          4         5         6   \\\n0    0.299403 -1.226624  1.498425 -1.176150   5.289853  0.208297  2.404498   \n1   -1.174176  0.332157  0.949919 -1.285328   2.199061 -0.151268 -0.427039   \n2    1.192222 -0.414371  0.067054 -2.233568   3.658881  0.089007  0.203439   \n3    1.573270 -0.580318 -0.866332 -0.603812   3.125716  0.870321 -0.161992   \n4   -0.613071 -0.644204  1.112558 -0.032397   3.490142 -0.011935  1.443521   \n..        ...       ...       ...       ...        ...       ...       ...   \n995 -0.310429  0.826811 -0.952245  0.768850   1.877520  1.320646  1.944609   \n996 -1.853879  0.246726  0.459921 -2.074267   7.599220 -0.138355 -4.501900   \n997  0.912748 -1.734039 -1.047035  0.217573  13.457812  0.162771 -2.250521   \n998  2.439780 -0.735511 -0.902426  1.365036 -10.430299 -0.856859  2.686474   \n999  0.228994 -0.085453  0.876582  1.057401  -1.404015 -1.091965  0.639176   \n\n           7         8         9   ...        30        31        32  \\\n0    1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057   \n1    2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836   \n2   -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521   \n3    4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110   \n4   -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579   \n..        ...       ...       ...  ...       ...       ...       ...   \n995  1.191420 -0.127724  0.070937  ... -0.600411 -0.383792  0.745596   \n996  0.630634 -1.590533 -1.112949  ...  0.361736  0.240052 -0.856196   \n997  2.216161 -0.378326  0.642114  ...  1.195896 -1.073806 -2.754369   \n998  0.292035  0.585388 -0.876965  ...  2.262326 -0.039488  0.773876   \n999  0.701332 -0.906577 -0.390940  ...  0.471415  1.024757 -1.796571   \n\n           33        34        35        36        37        38        39  \n0    0.293024  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n1    0.468579 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n2    0.856988 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n3   -1.065252  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n4   -0.205029 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n..        ...       ...       ...       ...       ...       ...       ...  \n995 -0.698598 -2.729937 -0.431535  0.372873  1.019092 -2.672811 -0.295141  \n996 -0.072481 -2.935896  0.582411 -2.613407  0.036687  2.809310  4.412567  \n997  1.814864 -4.190105 -1.116441 -2.100125  0.061513  0.895536  0.813686  \n998 -0.916066  2.604827 -0.649874 -3.423674  0.229748 -2.311088 -3.422217  \n999  0.603161  0.862705  0.747234  3.275681  0.400372 -3.431031  2.370080  \n\n[1000 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.299403</td>\n      <td>-1.226624</td>\n      <td>1.498425</td>\n      <td>-1.176150</td>\n      <td>5.289853</td>\n      <td>0.208297</td>\n      <td>2.404498</td>\n      <td>1.594506</td>\n      <td>-0.051608</td>\n      <td>0.663234</td>\n      <td>...</td>\n      <td>-0.850465</td>\n      <td>-0.622990</td>\n      <td>-1.833057</td>\n      <td>0.293024</td>\n      <td>3.552681</td>\n      <td>0.717611</td>\n      <td>3.305972</td>\n      <td>-2.715559</td>\n      <td>-2.682409</td>\n      <td>0.101050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.174176</td>\n      <td>0.332157</td>\n      <td>0.949919</td>\n      <td>-1.285328</td>\n      <td>2.199061</td>\n      <td>-0.151268</td>\n      <td>-0.427039</td>\n      <td>2.619246</td>\n      <td>-0.765884</td>\n      <td>-0.093780</td>\n      <td>...</td>\n      <td>-0.819750</td>\n      <td>0.012037</td>\n      <td>2.038836</td>\n      <td>0.468579</td>\n      <td>-0.517657</td>\n      <td>0.422326</td>\n      <td>0.803699</td>\n      <td>1.213219</td>\n      <td>1.382932</td>\n      <td>-1.817761</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.192222</td>\n      <td>-0.414371</td>\n      <td>0.067054</td>\n      <td>-2.233568</td>\n      <td>3.658881</td>\n      <td>0.089007</td>\n      <td>0.203439</td>\n      <td>-4.219054</td>\n      <td>-1.184919</td>\n      <td>-1.240310</td>\n      <td>...</td>\n      <td>-0.604501</td>\n      <td>0.750054</td>\n      <td>-3.360521</td>\n      <td>0.856988</td>\n      <td>-2.751451</td>\n      <td>-1.582735</td>\n      <td>1.672246</td>\n      <td>0.656438</td>\n      <td>-0.932473</td>\n      <td>2.987436</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.573270</td>\n      <td>-0.580318</td>\n      <td>-0.866332</td>\n      <td>-0.603812</td>\n      <td>3.125716</td>\n      <td>0.870321</td>\n      <td>-0.161992</td>\n      <td>4.499666</td>\n      <td>1.038741</td>\n      <td>-1.092716</td>\n      <td>...</td>\n      <td>1.022959</td>\n      <td>1.275598</td>\n      <td>-3.480110</td>\n      <td>-1.065252</td>\n      <td>2.153133</td>\n      <td>1.563539</td>\n      <td>2.767117</td>\n      <td>0.215748</td>\n      <td>0.619645</td>\n      <td>1.883397</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.613071</td>\n      <td>-0.644204</td>\n      <td>1.112558</td>\n      <td>-0.032397</td>\n      <td>3.490142</td>\n      <td>-0.011935</td>\n      <td>1.443521</td>\n      <td>-4.290282</td>\n      <td>-1.761308</td>\n      <td>0.807652</td>\n      <td>...</td>\n      <td>0.513906</td>\n      <td>-1.803473</td>\n      <td>0.518579</td>\n      <td>-0.205029</td>\n      <td>-4.744566</td>\n      <td>-1.520015</td>\n      <td>1.830651</td>\n      <td>0.870772</td>\n      <td>-1.894609</td>\n      <td>0.408332</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>-0.310429</td>\n      <td>0.826811</td>\n      <td>-0.952245</td>\n      <td>0.768850</td>\n      <td>1.877520</td>\n      <td>1.320646</td>\n      <td>1.944609</td>\n      <td>1.191420</td>\n      <td>-0.127724</td>\n      <td>0.070937</td>\n      <td>...</td>\n      <td>-0.600411</td>\n      <td>-0.383792</td>\n      <td>0.745596</td>\n      <td>-0.698598</td>\n      <td>-2.729937</td>\n      <td>-0.431535</td>\n      <td>0.372873</td>\n      <td>1.019092</td>\n      <td>-2.672811</td>\n      <td>-0.295141</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>-1.853879</td>\n      <td>0.246726</td>\n      <td>0.459921</td>\n      <td>-2.074267</td>\n      <td>7.599220</td>\n      <td>-0.138355</td>\n      <td>-4.501900</td>\n      <td>0.630634</td>\n      <td>-1.590533</td>\n      <td>-1.112949</td>\n      <td>...</td>\n      <td>0.361736</td>\n      <td>0.240052</td>\n      <td>-0.856196</td>\n      <td>-0.072481</td>\n      <td>-2.935896</td>\n      <td>0.582411</td>\n      <td>-2.613407</td>\n      <td>0.036687</td>\n      <td>2.809310</td>\n      <td>4.412567</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>0.912748</td>\n      <td>-1.734039</td>\n      <td>-1.047035</td>\n      <td>0.217573</td>\n      <td>13.457812</td>\n      <td>0.162771</td>\n      <td>-2.250521</td>\n      <td>2.216161</td>\n      <td>-0.378326</td>\n      <td>0.642114</td>\n      <td>...</td>\n      <td>1.195896</td>\n      <td>-1.073806</td>\n      <td>-2.754369</td>\n      <td>1.814864</td>\n      <td>-4.190105</td>\n      <td>-1.116441</td>\n      <td>-2.100125</td>\n      <td>0.061513</td>\n      <td>0.895536</td>\n      <td>0.813686</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2.439780</td>\n      <td>-0.735511</td>\n      <td>-0.902426</td>\n      <td>1.365036</td>\n      <td>-10.430299</td>\n      <td>-0.856859</td>\n      <td>2.686474</td>\n      <td>0.292035</td>\n      <td>0.585388</td>\n      <td>-0.876965</td>\n      <td>...</td>\n      <td>2.262326</td>\n      <td>-0.039488</td>\n      <td>0.773876</td>\n      <td>-0.916066</td>\n      <td>2.604827</td>\n      <td>-0.649874</td>\n      <td>-3.423674</td>\n      <td>0.229748</td>\n      <td>-2.311088</td>\n      <td>-3.422217</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0.228994</td>\n      <td>-0.085453</td>\n      <td>0.876582</td>\n      <td>1.057401</td>\n      <td>-1.404015</td>\n      <td>-1.091965</td>\n      <td>0.639176</td>\n      <td>0.701332</td>\n      <td>-0.906577</td>\n      <td>-0.390940</td>\n      <td>...</td>\n      <td>0.471415</td>\n      <td>1.024757</td>\n      <td>-1.796571</td>\n      <td>0.603161</td>\n      <td>0.862705</td>\n      <td>0.747234</td>\n      <td>3.275681</td>\n      <td>0.400372</td>\n      <td>-3.431031</td>\n      <td>2.370080</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 40)"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "X_train = train_data.copy()\n",
    "y_train = y_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1000 non-null   float64\n",
      " 1   1       1000 non-null   float64\n",
      " 2   2       1000 non-null   float64\n",
      " 3   3       1000 non-null   float64\n",
      " 4   4       1000 non-null   float64\n",
      " 5   5       1000 non-null   float64\n",
      " 6   6       1000 non-null   float64\n",
      " 7   7       1000 non-null   float64\n",
      " 8   8       1000 non-null   float64\n",
      " 9   9       1000 non-null   float64\n",
      " 10  10      1000 non-null   float64\n",
      " 11  11      1000 non-null   float64\n",
      " 12  12      1000 non-null   float64\n",
      " 13  13      1000 non-null   float64\n",
      " 14  14      1000 non-null   float64\n",
      " 15  15      1000 non-null   float64\n",
      " 16  16      1000 non-null   float64\n",
      " 17  17      1000 non-null   float64\n",
      " 18  18      1000 non-null   float64\n",
      " 19  19      1000 non-null   float64\n",
      " 20  20      1000 non-null   float64\n",
      " 21  21      1000 non-null   float64\n",
      " 22  22      1000 non-null   float64\n",
      " 23  23      1000 non-null   float64\n",
      " 24  24      1000 non-null   float64\n",
      " 25  25      1000 non-null   float64\n",
      " 26  26      1000 non-null   float64\n",
      " 27  27      1000 non-null   float64\n",
      " 28  28      1000 non-null   float64\n",
      " 29  29      1000 non-null   float64\n",
      " 30  30      1000 non-null   float64\n",
      " 31  31      1000 non-null   float64\n",
      " 32  32      1000 non-null   float64\n",
      " 33  33      1000 non-null   float64\n",
      " 34  34      1000 non-null   float64\n",
      " 35  35      1000 non-null   float64\n",
      " 36  36      1000 non-null   float64\n",
      " 37  37      1000 non-null   float64\n",
      " 38  38      1000 non-null   float64\n",
      " 39  39      1000 non-null   float64\n",
      "dtypes: float64(40)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \nstd       1.008282     1.016298     0.979109     0.970575     4.538834   \nmin      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n75%       0.762520     0.682753     0.661434     0.640743     3.843172   \nmax       3.326246     3.583870     2.546507     3.088738    17.565345   \n\n                5            6            7            8            9   ...  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \nmean     -0.006250     0.497342    -0.037883     0.026391    -0.003597  ...   \nstd       0.989128     2.118819     2.232256     1.001064     1.013520  ...   \nmin      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812  ...   \n25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220  ...   \n50%       0.027041     0.582321     0.018809     0.022092    -0.036110  ...   \n75%       0.671456     1.913664     1.438304     0.741310     0.665364  ...   \nmax       3.102997     7.592666     7.130097     3.145258     3.919426  ...   \n\n                30           31           32           33           34  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.030651     0.022951    -0.542491    -0.011608    -0.483507   \nstd       1.011645     1.001375     2.239939     1.022456     2.121281   \nmin      -3.379194    -2.971125    -7.840890    -2.999564    -7.124105   \n25%      -0.659457    -0.696032    -2.121943    -0.664550    -1.879247   \n50%       0.049416     0.049778    -0.568262    -0.028097    -0.493575   \n75%       0.747031     0.699917     0.939348     0.651374     1.005795   \nmax       2.844792     3.688047     7.160379     3.353631     6.005818   \n\n                35           36           37           38           39  \ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \nmean      0.033371     0.567185     0.006849    -0.892659     0.609451  \nstd       1.007044     2.227876     0.997635     2.022022     2.045439  \nmin      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086  \n25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041  \n50%       0.037732     0.455474     0.038284    -0.855470     0.779944  \n75%       0.691800     2.122157     0.693535     0.388698     1.992193  \nmax       3.420561     6.603499     3.492548     5.774120     6.803984  \n\n[8 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>...</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.025596</td>\n      <td>-0.024526</td>\n      <td>-0.024088</td>\n      <td>-0.002271</td>\n      <td>1.092329</td>\n      <td>-0.006250</td>\n      <td>0.497342</td>\n      <td>-0.037883</td>\n      <td>0.026391</td>\n      <td>-0.003597</td>\n      <td>...</td>\n      <td>0.030651</td>\n      <td>0.022951</td>\n      <td>-0.542491</td>\n      <td>-0.011608</td>\n      <td>-0.483507</td>\n      <td>0.033371</td>\n      <td>0.567185</td>\n      <td>0.006849</td>\n      <td>-0.892659</td>\n      <td>0.609451</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.008282</td>\n      <td>1.016298</td>\n      <td>0.979109</td>\n      <td>0.970575</td>\n      <td>4.538834</td>\n      <td>0.989128</td>\n      <td>2.118819</td>\n      <td>2.232256</td>\n      <td>1.001064</td>\n      <td>1.013520</td>\n      <td>...</td>\n      <td>1.011645</td>\n      <td>1.001375</td>\n      <td>2.239939</td>\n      <td>1.022456</td>\n      <td>2.121281</td>\n      <td>1.007044</td>\n      <td>2.227876</td>\n      <td>0.997635</td>\n      <td>2.022022</td>\n      <td>2.045439</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.365711</td>\n      <td>-3.492086</td>\n      <td>-2.695602</td>\n      <td>-3.460471</td>\n      <td>-16.421901</td>\n      <td>-3.041250</td>\n      <td>-7.224761</td>\n      <td>-6.509084</td>\n      <td>-3.145588</td>\n      <td>-2.749812</td>\n      <td>...</td>\n      <td>-3.379194</td>\n      <td>-2.971125</td>\n      <td>-7.840890</td>\n      <td>-2.999564</td>\n      <td>-7.124105</td>\n      <td>-2.952358</td>\n      <td>-5.452254</td>\n      <td>-3.473913</td>\n      <td>-8.051722</td>\n      <td>-7.799086</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.669010</td>\n      <td>-0.693937</td>\n      <td>-0.698830</td>\n      <td>-0.617557</td>\n      <td>-1.801997</td>\n      <td>-0.732265</td>\n      <td>-0.838619</td>\n      <td>-1.604037</td>\n      <td>-0.677562</td>\n      <td>-0.682220</td>\n      <td>...</td>\n      <td>-0.659457</td>\n      <td>-0.696032</td>\n      <td>-2.121943</td>\n      <td>-0.664550</td>\n      <td>-1.879247</td>\n      <td>-0.642861</td>\n      <td>-1.059786</td>\n      <td>-0.691162</td>\n      <td>-2.220126</td>\n      <td>-0.565041</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.027895</td>\n      <td>-0.033194</td>\n      <td>0.008145</td>\n      <td>0.002327</td>\n      <td>0.862818</td>\n      <td>0.027041</td>\n      <td>0.582321</td>\n      <td>0.018809</td>\n      <td>0.022092</td>\n      <td>-0.036110</td>\n      <td>...</td>\n      <td>0.049416</td>\n      <td>0.049778</td>\n      <td>-0.568262</td>\n      <td>-0.028097</td>\n      <td>-0.493575</td>\n      <td>0.037732</td>\n      <td>0.455474</td>\n      <td>0.038284</td>\n      <td>-0.855470</td>\n      <td>0.779944</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.762520</td>\n      <td>0.682753</td>\n      <td>0.661434</td>\n      <td>0.640743</td>\n      <td>3.843172</td>\n      <td>0.671456</td>\n      <td>1.913664</td>\n      <td>1.438304</td>\n      <td>0.741310</td>\n      <td>0.665364</td>\n      <td>...</td>\n      <td>0.747031</td>\n      <td>0.699917</td>\n      <td>0.939348</td>\n      <td>0.651374</td>\n      <td>1.005795</td>\n      <td>0.691800</td>\n      <td>2.122157</td>\n      <td>0.693535</td>\n      <td>0.388698</td>\n      <td>1.992193</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.326246</td>\n      <td>3.583870</td>\n      <td>2.546507</td>\n      <td>3.088738</td>\n      <td>17.565345</td>\n      <td>3.102997</td>\n      <td>7.592666</td>\n      <td>7.130097</td>\n      <td>3.145258</td>\n      <td>3.919426</td>\n      <td>...</td>\n      <td>2.844792</td>\n      <td>3.688047</td>\n      <td>7.160379</td>\n      <td>3.353631</td>\n      <td>6.005818</td>\n      <td>3.420561</td>\n      <td>6.603499</td>\n      <td>3.492548</td>\n      <td>5.774120</td>\n      <td>6.803984</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     0\n9     0\n10    0\n11    0\n12    0\n13    0\n14    0\n15    0\n16    0\n17    0\n18    0\n19    0\n20    0\n21    0\n22    0\n23    0\n24    0\n25    0\n26    0\n27    0\n28    0\n29    0\n30    0\n31    0\n32    0\n33    0\n34    0\n35    0\n36    0\n37    0\n38    0\n39    0\ndtype: int64"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<AxesSubplot:title={'center':'0'}>,\n        <AxesSubplot:title={'center':'1'}>,\n        <AxesSubplot:title={'center':'2'}>,\n        <AxesSubplot:title={'center':'3'}>,\n        <AxesSubplot:title={'center':'4'}>,\n        <AxesSubplot:title={'center':'5'}>],\n       [<AxesSubplot:title={'center':'6'}>,\n        <AxesSubplot:title={'center':'7'}>,\n        <AxesSubplot:title={'center':'8'}>,\n        <AxesSubplot:title={'center':'9'}>,\n        <AxesSubplot:title={'center':'10'}>,\n        <AxesSubplot:title={'center':'11'}>],\n       [<AxesSubplot:title={'center':'12'}>,\n        <AxesSubplot:title={'center':'13'}>,\n        <AxesSubplot:title={'center':'14'}>,\n        <AxesSubplot:title={'center':'15'}>,\n        <AxesSubplot:title={'center':'16'}>,\n        <AxesSubplot:title={'center':'17'}>],\n       [<AxesSubplot:title={'center':'18'}>,\n        <AxesSubplot:title={'center':'19'}>,\n        <AxesSubplot:title={'center':'20'}>,\n        <AxesSubplot:title={'center':'21'}>,\n        <AxesSubplot:title={'center':'22'}>,\n        <AxesSubplot:title={'center':'23'}>],\n       [<AxesSubplot:title={'center':'24'}>,\n        <AxesSubplot:title={'center':'25'}>,\n        <AxesSubplot:title={'center':'26'}>,\n        <AxesSubplot:title={'center':'27'}>,\n        <AxesSubplot:title={'center':'28'}>,\n        <AxesSubplot:title={'center':'29'}>],\n       [<AxesSubplot:title={'center':'30'}>,\n        <AxesSubplot:title={'center':'31'}>,\n        <AxesSubplot:title={'center':'32'}>,\n        <AxesSubplot:title={'center':'33'}>,\n        <AxesSubplot:title={'center':'34'}>,\n        <AxesSubplot:title={'center':'35'}>],\n       [<AxesSubplot:title={'center':'36'}>,\n        <AxesSubplot:title={'center':'37'}>,\n        <AxesSubplot:title={'center':'38'}>,\n        <AxesSubplot:title={'center':'39'}>, <AxesSubplot:>,\n        <AxesSubplot:>]], dtype=object)"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 42 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X_train.hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "           1         0         0         1         0         1         0  \\\n0  -0.029022  1.000000  1.000000 -0.029022  1.000000 -0.029022  1.000000   \n1   1.000000 -0.029022 -0.029022  1.000000 -0.029022  1.000000 -0.029022   \n2   0.014202  0.033437  0.033437  0.014202  0.033437  0.014202  0.033437   \n3   0.009663  0.012054  0.012054  0.009663  0.012054  0.009663  0.012054   \n4   0.044758 -0.022404 -0.022404  0.044758 -0.022404  0.044758 -0.022404   \n5  -0.034173  0.037209  0.037209 -0.034173  0.037209 -0.034173  0.037209   \n6  -0.008474  0.019134  0.019134 -0.008474  0.019134 -0.008474  0.019134   \n7   0.006568  0.015277  0.015277  0.006568  0.015277  0.006568  0.015277   \n8   0.039895 -0.045568 -0.045568  0.039895 -0.045568  0.039895 -0.045568   \n9   0.008368 -0.023777 -0.023777  0.008368 -0.023777  0.008368 -0.023777   \n10  0.022105 -0.037427 -0.037427  0.022105 -0.037427  0.022105 -0.037427   \n11 -0.034953  0.012477  0.012477 -0.034953  0.012477 -0.034953  0.012477   \n12 -0.065364 -0.004410 -0.004410 -0.065364 -0.004410 -0.065364 -0.004410   \n13 -0.039695  0.044999  0.044999 -0.039695  0.044999 -0.039695  0.044999   \n14 -0.069600  0.002984  0.002984 -0.069600  0.002984 -0.069600  0.002984   \n15 -0.001228  0.006890  0.006890 -0.001228  0.006890 -0.001228  0.006890   \n16 -0.033658  0.023151  0.023151 -0.033658  0.023151 -0.033658  0.023151   \n17  0.044709  0.039499  0.039499  0.044709  0.039499  0.044709  0.039499   \n18  0.018864 -0.051614 -0.051614  0.018864 -0.051614  0.018864 -0.051614   \n19  0.009298  0.004408  0.004408  0.009298  0.004408  0.009298  0.004408   \n20  0.021246 -0.001347 -0.001347  0.021246 -0.001347  0.021246 -0.001347   \n21  0.020263  0.016485  0.016485  0.020263  0.016485  0.020263  0.016485   \n22  0.044744  0.021047  0.021047  0.044744  0.021047  0.044744  0.021047   \n23  0.051050 -0.020664 -0.020664  0.051050 -0.020664  0.051050 -0.020664   \n24  0.020862 -0.028256 -0.028256  0.020862 -0.028256  0.020862 -0.028256   \n25  0.019272 -0.014671 -0.014671  0.019272 -0.014671  0.019272 -0.014671   \n26  0.010341  0.047728  0.047728  0.010341  0.047728  0.010341  0.047728   \n27 -0.002228 -0.060396 -0.060396 -0.002228 -0.060396 -0.002228 -0.060396   \n28 -0.067760  0.026154  0.026154 -0.067760  0.026154 -0.067760  0.026154   \n29 -0.010763  0.031174  0.031174 -0.010763  0.031174 -0.010763  0.031174   \n30 -0.000782  0.012446  0.012446 -0.000782  0.012446 -0.000782  0.012446   \n31 -0.052864  0.023033  0.023033 -0.052864  0.023033 -0.052864  0.023033   \n32  0.005583 -0.004701 -0.004701  0.005583 -0.004701  0.005583 -0.004701   \n33  0.009125  0.005180  0.005180  0.009125  0.005180  0.009125  0.005180   \n34 -0.026617  0.012961  0.012961 -0.026617  0.012961 -0.026617  0.012961   \n35  0.053087  0.047455  0.047455  0.053087  0.047455  0.053087  0.047455   \n36  0.039265 -0.026327 -0.026327  0.039265 -0.026327  0.039265 -0.026327   \n37  0.019537  0.038844  0.038844  0.019537  0.038844  0.019537  0.038844   \n38 -0.046295  0.016098  0.016098 -0.046295  0.016098 -0.046295  0.016098   \n39 -0.005667 -0.045840 -0.045840 -0.005667 -0.045840 -0.005667 -0.045840   \n\n           1         1         0  ...         1         1         1         1  \\\n0  -0.029022 -0.029022  1.000000  ... -0.029022 -0.029022 -0.029022 -0.029022   \n1   1.000000  1.000000 -0.029022  ...  1.000000  1.000000  1.000000  1.000000   \n2   0.014202  0.014202  0.033437  ...  0.014202  0.014202  0.014202  0.014202   \n3   0.009663  0.009663  0.012054  ...  0.009663  0.009663  0.009663  0.009663   \n4   0.044758  0.044758 -0.022404  ...  0.044758  0.044758  0.044758  0.044758   \n5  -0.034173 -0.034173  0.037209  ... -0.034173 -0.034173 -0.034173 -0.034173   \n6  -0.008474 -0.008474  0.019134  ... -0.008474 -0.008474 -0.008474 -0.008474   \n7   0.006568  0.006568  0.015277  ...  0.006568  0.006568  0.006568  0.006568   \n8   0.039895  0.039895 -0.045568  ...  0.039895  0.039895  0.039895  0.039895   \n9   0.008368  0.008368 -0.023777  ...  0.008368  0.008368  0.008368  0.008368   \n10  0.022105  0.022105 -0.037427  ...  0.022105  0.022105  0.022105  0.022105   \n11 -0.034953 -0.034953  0.012477  ... -0.034953 -0.034953 -0.034953 -0.034953   \n12 -0.065364 -0.065364 -0.004410  ... -0.065364 -0.065364 -0.065364 -0.065364   \n13 -0.039695 -0.039695  0.044999  ... -0.039695 -0.039695 -0.039695 -0.039695   \n14 -0.069600 -0.069600  0.002984  ... -0.069600 -0.069600 -0.069600 -0.069600   \n15 -0.001228 -0.001228  0.006890  ... -0.001228 -0.001228 -0.001228 -0.001228   \n16 -0.033658 -0.033658  0.023151  ... -0.033658 -0.033658 -0.033658 -0.033658   \n17  0.044709  0.044709  0.039499  ...  0.044709  0.044709  0.044709  0.044709   \n18  0.018864  0.018864 -0.051614  ...  0.018864  0.018864  0.018864  0.018864   \n19  0.009298  0.009298  0.004408  ...  0.009298  0.009298  0.009298  0.009298   \n20  0.021246  0.021246 -0.001347  ...  0.021246  0.021246  0.021246  0.021246   \n21  0.020263  0.020263  0.016485  ...  0.020263  0.020263  0.020263  0.020263   \n22  0.044744  0.044744  0.021047  ...  0.044744  0.044744  0.044744  0.044744   \n23  0.051050  0.051050 -0.020664  ...  0.051050  0.051050  0.051050  0.051050   \n24  0.020862  0.020862 -0.028256  ...  0.020862  0.020862  0.020862  0.020862   \n25  0.019272  0.019272 -0.014671  ...  0.019272  0.019272  0.019272  0.019272   \n26  0.010341  0.010341  0.047728  ...  0.010341  0.010341  0.010341  0.010341   \n27 -0.002228 -0.002228 -0.060396  ... -0.002228 -0.002228 -0.002228 -0.002228   \n28 -0.067760 -0.067760  0.026154  ... -0.067760 -0.067760 -0.067760 -0.067760   \n29 -0.010763 -0.010763  0.031174  ... -0.010763 -0.010763 -0.010763 -0.010763   \n30 -0.000782 -0.000782  0.012446  ... -0.000782 -0.000782 -0.000782 -0.000782   \n31 -0.052864 -0.052864  0.023033  ... -0.052864 -0.052864 -0.052864 -0.052864   \n32  0.005583  0.005583 -0.004701  ...  0.005583  0.005583  0.005583  0.005583   \n33  0.009125  0.009125  0.005180  ...  0.009125  0.009125  0.009125  0.009125   \n34 -0.026617 -0.026617  0.012961  ... -0.026617 -0.026617 -0.026617 -0.026617   \n35  0.053087  0.053087  0.047455  ...  0.053087  0.053087  0.053087  0.053087   \n36  0.039265  0.039265 -0.026327  ...  0.039265  0.039265  0.039265  0.039265   \n37  0.019537  0.019537  0.038844  ...  0.019537  0.019537  0.019537  0.019537   \n38 -0.046295 -0.046295  0.016098  ... -0.046295 -0.046295 -0.046295 -0.046295   \n39 -0.005667 -0.005667 -0.045840  ... -0.005667 -0.005667 -0.005667 -0.005667   \n\n           0         0         1         1         0         0  \n0   1.000000  1.000000 -0.029022 -0.029022  1.000000  1.000000  \n1  -0.029022 -0.029022  1.000000  1.000000 -0.029022 -0.029022  \n2   0.033437  0.033437  0.014202  0.014202  0.033437  0.033437  \n3   0.012054  0.012054  0.009663  0.009663  0.012054  0.012054  \n4  -0.022404 -0.022404  0.044758  0.044758 -0.022404 -0.022404  \n5   0.037209  0.037209 -0.034173 -0.034173  0.037209  0.037209  \n6   0.019134  0.019134 -0.008474 -0.008474  0.019134  0.019134  \n7   0.015277  0.015277  0.006568  0.006568  0.015277  0.015277  \n8  -0.045568 -0.045568  0.039895  0.039895 -0.045568 -0.045568  \n9  -0.023777 -0.023777  0.008368  0.008368 -0.023777 -0.023777  \n10 -0.037427 -0.037427  0.022105  0.022105 -0.037427 -0.037427  \n11  0.012477  0.012477 -0.034953 -0.034953  0.012477  0.012477  \n12 -0.004410 -0.004410 -0.065364 -0.065364 -0.004410 -0.004410  \n13  0.044999  0.044999 -0.039695 -0.039695  0.044999  0.044999  \n14  0.002984  0.002984 -0.069600 -0.069600  0.002984  0.002984  \n15  0.006890  0.006890 -0.001228 -0.001228  0.006890  0.006890  \n16  0.023151  0.023151 -0.033658 -0.033658  0.023151  0.023151  \n17  0.039499  0.039499  0.044709  0.044709  0.039499  0.039499  \n18 -0.051614 -0.051614  0.018864  0.018864 -0.051614 -0.051614  \n19  0.004408  0.004408  0.009298  0.009298  0.004408  0.004408  \n20 -0.001347 -0.001347  0.021246  0.021246 -0.001347 -0.001347  \n21  0.016485  0.016485  0.020263  0.020263  0.016485  0.016485  \n22  0.021047  0.021047  0.044744  0.044744  0.021047  0.021047  \n23 -0.020664 -0.020664  0.051050  0.051050 -0.020664 -0.020664  \n24 -0.028256 -0.028256  0.020862  0.020862 -0.028256 -0.028256  \n25 -0.014671 -0.014671  0.019272  0.019272 -0.014671 -0.014671  \n26  0.047728  0.047728  0.010341  0.010341  0.047728  0.047728  \n27 -0.060396 -0.060396 -0.002228 -0.002228 -0.060396 -0.060396  \n28  0.026154  0.026154 -0.067760 -0.067760  0.026154  0.026154  \n29  0.031174  0.031174 -0.010763 -0.010763  0.031174  0.031174  \n30  0.012446  0.012446 -0.000782 -0.000782  0.012446  0.012446  \n31  0.023033  0.023033 -0.052864 -0.052864  0.023033  0.023033  \n32 -0.004701 -0.004701  0.005583  0.005583 -0.004701 -0.004701  \n33  0.005180  0.005180  0.009125  0.009125  0.005180  0.005180  \n34  0.012961  0.012961 -0.026617 -0.026617  0.012961  0.012961  \n35  0.047455  0.047455  0.053087  0.053087  0.047455  0.047455  \n36 -0.026327 -0.026327  0.039265  0.039265 -0.026327 -0.026327  \n37  0.038844  0.038844  0.019537  0.019537  0.038844  0.038844  \n38  0.016098  0.016098 -0.046295 -0.046295  0.016098  0.016098  \n39 -0.045840 -0.045840 -0.005667 -0.005667 -0.045840 -0.045840  \n\n[40 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>1</th>\n      <th>0</th>\n      <th>...</th>\n      <th>1</th>\n      <th>1</th>\n      <th>1</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.029022</td>\n      <td>-0.029022</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>0.033437</td>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>0.014202</td>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>...</td>\n      <td>0.014202</td>\n      <td>0.014202</td>\n      <td>0.014202</td>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>0.033437</td>\n      <td>0.014202</td>\n      <td>0.014202</td>\n      <td>0.033437</td>\n      <td>0.033437</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>0.012054</td>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>0.009663</td>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>...</td>\n      <td>0.009663</td>\n      <td>0.009663</td>\n      <td>0.009663</td>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>0.012054</td>\n      <td>0.009663</td>\n      <td>0.009663</td>\n      <td>0.012054</td>\n      <td>0.012054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>-0.022404</td>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>0.044758</td>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>...</td>\n      <td>0.044758</td>\n      <td>0.044758</td>\n      <td>0.044758</td>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>-0.022404</td>\n      <td>0.044758</td>\n      <td>0.044758</td>\n      <td>-0.022404</td>\n      <td>-0.022404</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>0.037209</td>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>-0.034173</td>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>...</td>\n      <td>-0.034173</td>\n      <td>-0.034173</td>\n      <td>-0.034173</td>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>0.037209</td>\n      <td>-0.034173</td>\n      <td>-0.034173</td>\n      <td>0.037209</td>\n      <td>0.037209</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>0.019134</td>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>-0.008474</td>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>...</td>\n      <td>-0.008474</td>\n      <td>-0.008474</td>\n      <td>-0.008474</td>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>0.019134</td>\n      <td>-0.008474</td>\n      <td>-0.008474</td>\n      <td>0.019134</td>\n      <td>0.019134</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>0.015277</td>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>0.006568</td>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>...</td>\n      <td>0.006568</td>\n      <td>0.006568</td>\n      <td>0.006568</td>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>0.015277</td>\n      <td>0.006568</td>\n      <td>0.006568</td>\n      <td>0.015277</td>\n      <td>0.015277</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>-0.045568</td>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>0.039895</td>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>...</td>\n      <td>0.039895</td>\n      <td>0.039895</td>\n      <td>0.039895</td>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>-0.045568</td>\n      <td>0.039895</td>\n      <td>0.039895</td>\n      <td>-0.045568</td>\n      <td>-0.045568</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>-0.023777</td>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>0.008368</td>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>...</td>\n      <td>0.008368</td>\n      <td>0.008368</td>\n      <td>0.008368</td>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>-0.023777</td>\n      <td>0.008368</td>\n      <td>0.008368</td>\n      <td>-0.023777</td>\n      <td>-0.023777</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>-0.037427</td>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>0.022105</td>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>...</td>\n      <td>0.022105</td>\n      <td>0.022105</td>\n      <td>0.022105</td>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>-0.037427</td>\n      <td>0.022105</td>\n      <td>0.022105</td>\n      <td>-0.037427</td>\n      <td>-0.037427</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>0.012477</td>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>-0.034953</td>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>...</td>\n      <td>-0.034953</td>\n      <td>-0.034953</td>\n      <td>-0.034953</td>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>0.012477</td>\n      <td>-0.034953</td>\n      <td>-0.034953</td>\n      <td>0.012477</td>\n      <td>0.012477</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>-0.004410</td>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>-0.065364</td>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>...</td>\n      <td>-0.065364</td>\n      <td>-0.065364</td>\n      <td>-0.065364</td>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>-0.004410</td>\n      <td>-0.065364</td>\n      <td>-0.065364</td>\n      <td>-0.004410</td>\n      <td>-0.004410</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>0.044999</td>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>-0.039695</td>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>...</td>\n      <td>-0.039695</td>\n      <td>-0.039695</td>\n      <td>-0.039695</td>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>0.044999</td>\n      <td>-0.039695</td>\n      <td>-0.039695</td>\n      <td>0.044999</td>\n      <td>0.044999</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>0.002984</td>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>-0.069600</td>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>...</td>\n      <td>-0.069600</td>\n      <td>-0.069600</td>\n      <td>-0.069600</td>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>0.002984</td>\n      <td>-0.069600</td>\n      <td>-0.069600</td>\n      <td>0.002984</td>\n      <td>0.002984</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>0.006890</td>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>-0.001228</td>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>...</td>\n      <td>-0.001228</td>\n      <td>-0.001228</td>\n      <td>-0.001228</td>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>0.006890</td>\n      <td>-0.001228</td>\n      <td>-0.001228</td>\n      <td>0.006890</td>\n      <td>0.006890</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>0.023151</td>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>-0.033658</td>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>...</td>\n      <td>-0.033658</td>\n      <td>-0.033658</td>\n      <td>-0.033658</td>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>0.023151</td>\n      <td>-0.033658</td>\n      <td>-0.033658</td>\n      <td>0.023151</td>\n      <td>0.023151</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>0.039499</td>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>0.044709</td>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>...</td>\n      <td>0.044709</td>\n      <td>0.044709</td>\n      <td>0.044709</td>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>0.039499</td>\n      <td>0.044709</td>\n      <td>0.044709</td>\n      <td>0.039499</td>\n      <td>0.039499</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>-0.051614</td>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>0.018864</td>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>...</td>\n      <td>0.018864</td>\n      <td>0.018864</td>\n      <td>0.018864</td>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>-0.051614</td>\n      <td>0.018864</td>\n      <td>0.018864</td>\n      <td>-0.051614</td>\n      <td>-0.051614</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>0.004408</td>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>0.009298</td>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>...</td>\n      <td>0.009298</td>\n      <td>0.009298</td>\n      <td>0.009298</td>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>0.004408</td>\n      <td>0.009298</td>\n      <td>0.009298</td>\n      <td>0.004408</td>\n      <td>0.004408</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>-0.001347</td>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>0.021246</td>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>...</td>\n      <td>0.021246</td>\n      <td>0.021246</td>\n      <td>0.021246</td>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>-0.001347</td>\n      <td>0.021246</td>\n      <td>0.021246</td>\n      <td>-0.001347</td>\n      <td>-0.001347</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>0.016485</td>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>0.020263</td>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>...</td>\n      <td>0.020263</td>\n      <td>0.020263</td>\n      <td>0.020263</td>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>0.016485</td>\n      <td>0.020263</td>\n      <td>0.020263</td>\n      <td>0.016485</td>\n      <td>0.016485</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>0.021047</td>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>0.044744</td>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>...</td>\n      <td>0.044744</td>\n      <td>0.044744</td>\n      <td>0.044744</td>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>0.021047</td>\n      <td>0.044744</td>\n      <td>0.044744</td>\n      <td>0.021047</td>\n      <td>0.021047</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>-0.020664</td>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>0.051050</td>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>...</td>\n      <td>0.051050</td>\n      <td>0.051050</td>\n      <td>0.051050</td>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>-0.020664</td>\n      <td>0.051050</td>\n      <td>0.051050</td>\n      <td>-0.020664</td>\n      <td>-0.020664</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>-0.028256</td>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>0.020862</td>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>...</td>\n      <td>0.020862</td>\n      <td>0.020862</td>\n      <td>0.020862</td>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>-0.028256</td>\n      <td>0.020862</td>\n      <td>0.020862</td>\n      <td>-0.028256</td>\n      <td>-0.028256</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>-0.014671</td>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>0.019272</td>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>...</td>\n      <td>0.019272</td>\n      <td>0.019272</td>\n      <td>0.019272</td>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>-0.014671</td>\n      <td>0.019272</td>\n      <td>0.019272</td>\n      <td>-0.014671</td>\n      <td>-0.014671</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>0.047728</td>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>0.010341</td>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>...</td>\n      <td>0.010341</td>\n      <td>0.010341</td>\n      <td>0.010341</td>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>0.047728</td>\n      <td>0.010341</td>\n      <td>0.010341</td>\n      <td>0.047728</td>\n      <td>0.047728</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>-0.060396</td>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>-0.002228</td>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>...</td>\n      <td>-0.002228</td>\n      <td>-0.002228</td>\n      <td>-0.002228</td>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>-0.060396</td>\n      <td>-0.002228</td>\n      <td>-0.002228</td>\n      <td>-0.060396</td>\n      <td>-0.060396</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>0.026154</td>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>-0.067760</td>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>...</td>\n      <td>-0.067760</td>\n      <td>-0.067760</td>\n      <td>-0.067760</td>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>0.026154</td>\n      <td>-0.067760</td>\n      <td>-0.067760</td>\n      <td>0.026154</td>\n      <td>0.026154</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>0.031174</td>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>-0.010763</td>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>...</td>\n      <td>-0.010763</td>\n      <td>-0.010763</td>\n      <td>-0.010763</td>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>0.031174</td>\n      <td>-0.010763</td>\n      <td>-0.010763</td>\n      <td>0.031174</td>\n      <td>0.031174</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>0.012446</td>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>-0.000782</td>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>...</td>\n      <td>-0.000782</td>\n      <td>-0.000782</td>\n      <td>-0.000782</td>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>0.012446</td>\n      <td>-0.000782</td>\n      <td>-0.000782</td>\n      <td>0.012446</td>\n      <td>0.012446</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>0.023033</td>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>-0.052864</td>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>...</td>\n      <td>-0.052864</td>\n      <td>-0.052864</td>\n      <td>-0.052864</td>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>0.023033</td>\n      <td>-0.052864</td>\n      <td>-0.052864</td>\n      <td>0.023033</td>\n      <td>0.023033</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>-0.004701</td>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>0.005583</td>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>...</td>\n      <td>0.005583</td>\n      <td>0.005583</td>\n      <td>0.005583</td>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>-0.004701</td>\n      <td>0.005583</td>\n      <td>0.005583</td>\n      <td>-0.004701</td>\n      <td>-0.004701</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>0.005180</td>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>0.009125</td>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>...</td>\n      <td>0.009125</td>\n      <td>0.009125</td>\n      <td>0.009125</td>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>0.005180</td>\n      <td>0.009125</td>\n      <td>0.009125</td>\n      <td>0.005180</td>\n      <td>0.005180</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>0.012961</td>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>-0.026617</td>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>...</td>\n      <td>-0.026617</td>\n      <td>-0.026617</td>\n      <td>-0.026617</td>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>0.012961</td>\n      <td>-0.026617</td>\n      <td>-0.026617</td>\n      <td>0.012961</td>\n      <td>0.012961</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>0.047455</td>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>0.053087</td>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>...</td>\n      <td>0.053087</td>\n      <td>0.053087</td>\n      <td>0.053087</td>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>0.047455</td>\n      <td>0.053087</td>\n      <td>0.053087</td>\n      <td>0.047455</td>\n      <td>0.047455</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>-0.026327</td>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>0.039265</td>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>...</td>\n      <td>0.039265</td>\n      <td>0.039265</td>\n      <td>0.039265</td>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>-0.026327</td>\n      <td>0.039265</td>\n      <td>0.039265</td>\n      <td>-0.026327</td>\n      <td>-0.026327</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>0.038844</td>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>0.019537</td>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>...</td>\n      <td>0.019537</td>\n      <td>0.019537</td>\n      <td>0.019537</td>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>0.038844</td>\n      <td>0.019537</td>\n      <td>0.019537</td>\n      <td>0.038844</td>\n      <td>0.038844</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>0.016098</td>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>-0.046295</td>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>...</td>\n      <td>-0.046295</td>\n      <td>-0.046295</td>\n      <td>-0.046295</td>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>0.016098</td>\n      <td>-0.046295</td>\n      <td>-0.046295</td>\n      <td>0.016098</td>\n      <td>0.016098</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>-0.045840</td>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>-0.005667</td>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>...</td>\n      <td>-0.005667</td>\n      <td>-0.005667</td>\n      <td>-0.005667</td>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>-0.045840</td>\n      <td>-0.005667</td>\n      <td>-0.005667</td>\n      <td>-0.045840</td>\n      <td>-0.045840</td>\n    </tr>\n  </tbody>\n</table>\n<p>40 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = X_train.corr()\n",
    "corr[y_data[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "0      21.373315\n1       1.735072\n2     -26.206324\n3      21.416064\n4     -33.399363\n         ...    \n995    -8.541896\n996    -2.666215\n997     8.269914\n998   -17.732640\n999    15.492088\nName: 39, Length: 1000, dtype: float64"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [x for x in X_train.columns if X_train[x].dtype == 'float64']\n",
    "X_train['39'] = 0\n",
    "for i in l:\n",
    "    X_train['39'] = X_train['39'] + X_train[i]\n",
    "X_train['39']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "0        7.325511\n1      -18.863280\n2      -10.107358\n3      -12.057489\n4       -7.994502\n          ...    \n8995     8.657272\n8996    22.571818\n8997    10.788161\n8998     8.250794\n8999    12.218932\nName: 39, Length: 9000, dtype: float64"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['39'] = 0\n",
    "for i in l:\n",
    "    test_data['39'] = test_data['39'] + test_data[i]\n",
    "test_data['39']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "test_data = sc.transform(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_18960/3698041140.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest_clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.86526946, 0.84984985, 0.84984985])"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(forest_clf, X_train, y_data, cv=3, scoring=\"accuracy\")\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:960: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:960: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:960: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n       1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 1, 1, 0, 1], dtype=int64)"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "score_ = cross_val_predict(forest_clf, X_train, y_data, cv=3)\n",
    "score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "SVC()"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC_clf = SVC()\n",
    "SVC_clf.fit(X_train, y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "d:\\my work\\kaggle\\sickit learn\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.87724551, 0.87087087, 0.83483483])"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "SVC_score = cross_val_score(SVC_clf, X_train, y_data, cv=3, scoring=\"accuracy\")\n",
    "SVC_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "y_forest_test_pred = forest_clf.predict(test_data)\n",
    "y_SVC_test_pred = SVC_clf.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_SVC_test_pred, columns=[\"Solution\"])\n",
    "submission.to_csv(\"submission.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "sub_data = pd.read_csv(\"D:\\my work\\kaggle\\sickit learn\\submission.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  Solution\n0              0         1\n1              1         0\n2              2         0\n3              3         0\n4              4         0\n...          ...       ...\n8995        8995         1\n8996        8996         1\n8997        8997         1\n8998        8998         0\n8999        8999         1\n\n[9000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Solution</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8995</th>\n      <td>8995</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8996</th>\n      <td>8996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8997</th>\n      <td>8997</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8998</th>\n      <td>8998</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8999</th>\n      <td>8999</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "sub_data[\"ID\"] = 0\n",
    "sub_data[\"Unnamed: 0\"]\n",
    "sub_data[\"ID\"] = 1 + sub_data[\"Unnamed: 0\"]\n",
    "sub_data.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "sub_data\n",
    "sub_data.to_csv(\"submission.csv\",)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}